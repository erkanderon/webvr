<pre class="metadata">
Shortname: webvr
Title: WebVR
Group: webvr
Status: ED
ED: https://w3c.github.io/webvr/
Repository: w3c/webvr
Level: 1
Mailing List Archives: https://lists.w3.org/Archives/Public/public-webvr/
Mailing List: public-webvr@mozilla.org

!Participate: <a href="https://github.com/w3c/webvr/issues/new">File an issue</a> (<a href="https://github.com/w3c/webvr/issues">open issues</a>)
!Participate: <a href="https://lists.w3.org/Archives/Public/public-webvr/">Mailing list archive</a>
!Participate: <a href="irc://irc.w3.org:6665/">W3C's #webvr IRC</a>

!Archive: <a href="archive/">Previous spec versions</a>

Editor: Vladimir Vukicevic, Mozilla https://mozilla.org/, vladimir@mozilla.com
Editor: Brandon Jones, Google http://google.com/, bajones@google.com
Editor: Kearwood Gilbert, Mozilla https://mozilla.org/, kgilbert@mozilla.com
Editor: Chris Van Wiemeersch, Mozilla https://mozilla.org/, cvan@mozilla.com
Abstract: This specification describes support for accessing virtual reality (VR) devices, including sensors and head-mounted displays on the Web.
</pre>

<pre class="anchors">
urlPrefix: http://www.w3.org/TR/hr-time/
    type: typedef; text: DOMHighResTimeStamp
    type: dfn; text: timestamp origin
urlPrefix: https://wiki.whatwg.org/wiki/OffscreenCanvas
    type: typedef; text: OffscreenCanvas
    type: dfn; text: offscreen canvas
urlPrefix: https://www.w3.org/TR/html51/webappapis.html
    type: dfn; text: window.requestAnimationFrame
urlPrefix: https://www.w3.org/TR/html5/
    type: interface; text: Document

spec: ECMAScript; urlPrefix: https://tc39.github.io/ecma262/#
    type: interface
        text: Promise; url:sec-promise-objects
</pre>


<b style="color: red; font-size: 1.3em">DO NOT IMPLEMENT</b>

<b>The version of the WebVR API represented in this document is incomplete and changing rapidly. Do not attempt to implement it at this time.</b>


Introduction {#intro}
=============

Hardware that enables Virtual Reality applications requires high-precision, low-latency interfaces to deliver an acceptable experience.
Other interfaces, such as device orientation events, can be repurposed to surface VR input but doing so dilutes the interface's original
intent and often does not provide the precision necessary for high-quality VR. The WebVR API provides purpose-built interfaces
to VR hardware to allow developers to build compelling, comfortable VR experiences.


Security, Privacy, and Comfort Considerations {#security}
=============================================

The WebVR API provides powerful new features which bring with them several unique privacy, security, and comfort risks that user agents must take steps to mitigate.

Gaze Tracking {#gazetracking-security}
-------------

While the API does not yet expose eye tracking capabilites a lot can be inferred about where the user is looking by tracking the orientation of their head. This is especially true of VR devices that have limited input capabilities, such as Google Carboard, which frequently require users to control a "gaze cursor" with their head orientation. This means that it may be possible for a malicious page to infer what a user is typing on a virtual keyboard or how they are interacting with a virtual UI based solely on monitoring their head movements. For example: if not prevented from doing so a page could estimate what URL a user is entering into the user agent's URL bar.

To prevent this risk the UA MUST [=blur active sessions=] when the users is interacting with sensitive, trusted UI such as URL bars or system dialogs. Additionally, to prevent a malicious page from being able to monitor input on a other pages the UA MUST [=blur active sessions=] on non-focused pages.

Trusted Environment {#trustedenvironment-security}
-------------------

If the virtual environment does not consistently track the user's head motion with low latency and at a high frame rate the user may become disoriented or physically ill. Since it is impossible to force pages to produce consistently performant and correct content the UA MUST provide a tracked, trusted environment and a [=VR Compositor=] which runs asynchronously from page content. The compositor is responsible for compositing the trusted and untrusted content. If content is not performant, does not submit frames, or terminates unexpectedly the UA should be able to continue presenting a responsive, trusted UI.

Additionally, page content has the ability to make users uncomfortable in ways not related to performance. Badly applied tracking, strobing colors, and content intended to offend, frighten, or intimidate are examples of content which may cause the user to want to quickly exit the VR experience. Removing the VR display in these cases may not always be a fast or practical option. To accomodate this the UA SHOULD provide users with an action, such as pressing a reserved hardware button or performing a gesture, that escapes out of WebVR content and displays the UA's trusted UI.

When navigating between pages in VR the UA should display trusted UI elements informing the user of the security information of the site they are navigating to which is normally presented by the 2D UI, such as the URL and encryption status.

Content Isolation {#contextisolation-security}
-----------------

The trusted UI must be drawing by an independent rendering context who's state is isolated from any rendering contexts used by the page. (For example, any WebGL rendering contexts.) This is to prevent the page from corrupting the state of the trusted UI's context, which may prevent it from properly rendering a tracked environment. It also prevents the possibility of the page being able to capture imagery from the trusted UI, which could lead to private information being leaked.

Also, to prevent CORS-related vulnerabilities each page will see a new instance of objects returned by the API, such as {{VRDisplay}} and {{VRSession}}. Attributes such as the {{VRCanvasLayer/source}} set by one page must not be able to be read by another. Similarly, methods invoked on the API MUST NOT cause an observable state change on other pages. For example: No method will be exposed that enables a system-level orientation reset, as this could be called repeatedly by a malicious page to prevent other pages from tracking properly. The UA MUST, however, respect system-level orientation resets triggered by a user gesture or system menu.


Display Enumeration {#displayenumeration}
===================

VR {#vr-interface}
----

<pre class="idl">
interface VR : EventTarget {
  // Methods
  Promise&lt;sequence&lt;VRDisplay&gt;&gt; getDisplays();

  // Events
  attribute EventHandler ondisplayconnect;
  attribute EventHandler ondisplaydisconnect;
  attribute EventHandler onnavigate;
};
</pre>

<dfn method for="VR">getDisplays()</dfn>
Return a Promise which resolves to a list of available {{VRDisplay}}s.

<dfn attribute for="VR">ondisplayconnect</dfn> is an <a>Event handler IDL attribute</a> for the {{displayconnect}} event type.

<dfn attribute for="VR">ondisplaydisconnect</dfn> is an <a>Event handler IDL attribute</a> for the {{displaydisconnect}} event type.

<dfn attribute for="VR">onnavigate</dfn> is an <a>Event handler IDL attribute</a> for the {{navigate}} event type.


VRDisplay {#vrdisplay-interface}
---------

<pre class="idl">
interface VRDisplay : EventTarget {
  // Attributes
  readonly attribute DOMString displayName;
  readonly attribute boolean isExternal;

  attribute VRSession? activeSession;

  // Methods
  Promise&lt;boolean&gt; supportsSession(VRSessionCreateParametersInit parameters);
  Promise&lt;VRSession&gt; requestSession(VRSessionCreateParametersInit parameters);

  // Events
  attribute EventHandler onsessionchange;
  attribute EventHandler onactivate;
  attribute EventHandler ondeactivate;
};
</pre>

A {{VRDisplay}} represents a physical unit of VR hardware that can present imagery to the user somehow. On desktop devices this may take the form of a headset peripheral; on mobile devices it may represent the device itself in conjunction with a viewer harness. It may also represent devices without the ability to present content in stereo but with advanced (6DoF) tracking capabilities.

<dfn attribute for="VRDisplay">displayName</dfn> returns a human readable string describing the {{VRDisplay}}.

<dfn attribute for="VRDisplay">isExternal</dfn> returns true if the {{VRDisplay}} hardware is a separate physical display from the system's main display.

A {{VRDisplay}} has an <dfn for="VRDisplay">active session</dfn>, initially <code>null</code>, which is the {{VRSession}} that is currently accessing and/or presenting to the display. Only one session can be active for a given display at a time.

The <dfn method for="VRDisplay">requestSession()</dfn> method sets or retrieves the [=active session=]. When invoked it MUST return <a>a new Promise</a> |promise| and run the following steps <a>in parallel</a>:

 1. If the requested [=session description=] is not supported by the display, <a>reject</a> |promise| and abort these steps.
 1. If the display's [=active session=] matches the requested [=session description=], <a>resolve</a> |promise| with the [=active session=] and abort these steps.
 1. If the requested [=session description=] requires a user gesture and the algorithm is not <a>triggered by user activation</a> <a>reject</a> |promise| and abort these steps.
 1. If another page has an [=presenting=] [=active session=] for the display, <a>reject</a> |promise| and abort these steps.
 1. Let |nextSession| be a new {{VRSession}} which matches the [=session description=].
 1. Let |prevSession| be the current [=active session=].
 1. <a>Fire an event</a> named {{sessionchange}} on the display with it's {{session}} attribute initialized to |nextSession|.
 1. Set the [=active session=] to |nextSession|.
 1. If |prevSession| is not null, [=end the session=].
 1. <a>Resolve</a> |promise| with the [=active session=].

When the <dfn method for="VRDisplay">supportsSession()</dfn> method is invoked it MUST return <a>a new Promise</a> |promise| and run the following steps <a>in parallel</a>:

 1. If the requested [=session description=] is supported by the display, <a>resolve</a> |promise| with true.
 1. Else <a>resolve</a> |promise| with false.

The <dfn attribute for="VRDisplay">activeSession</dfn> IDL attribute's getter
MUST return the {{VRDisplay}}'s [=active session=].

<dfn attribute for="VRDisplay">onsessionchange</dfn> is an <a>Event handler IDL attribute</a> for the {{sessionchange}} event type.

<dfn attribute for="VRDisplay">onactivate</dfn> is an <a>Event handler IDL attribute</a> for the {{activate}} event type.

<dfn attribute for="VRDisplay">ondeactivate</dfn> is an <a>Event handler IDL attribute</a> for the {{deactivate}} event type.


<div class="example">
The following code finds the first available {{VRDisplay}}.

<pre highlight="js">
let vrDisplay;

navigator.vr.getDisplays().then(displays => {
  // Use the first display in the array if one is available. If multiple
  // displays are present, you may want to present the user with a way to
  // select which display to use.
  if (displays.length > 0) {
    vrDisplay = displays[0];
  }
});
</pre>
</div>


Presentation {#presentation}
============

VRSessionCreateParameters {#vrsessioncreateparameters-interface}
-------------------------

The {{VRSessionCreateParameters}} interface

<pre class="idl">
dictionary VRSessionCreateParametersInit {
  required boolean present = true;
};

interface VRSessionCreateParameters {
  readonly attribute boolean present;
};
</pre>

<dfn attribute for="VRSessionCreateParameters">present</dfn>

</div>

VRSession {#vrsession-interface}
---------

The {{VRSession}} interface

<pre class="idl">
interface VRSession : EventTarget {
  // Attributes
  readonly attribute VRSessionCreateParameters createParameters;

  attribute double depthNear;
  attribute double depthFar;
  attribute VRLayer baseLayer;

  // Methods
  VRSourceProperties getSourceProperties(optional float scale);
  Promise&lt;VRFrameOfReference&gt; createFrameOfReference(VRFrameOfReferenceType type);
  VRDisplayPose? getDisplayPose(VRCoordinateSystem coordinateSystem);
  Promise&lt;VRPlayAreaBounds&gt; getPlayAreaBounds(VRCoordinateSystem coordinateSystem);
  Promise&lt;void&gt; endSession();

  // Events
  attribute EventHandler onblur;
  attribute EventHandler onfocus;
  attribute EventHandler onresetpose;
};
</pre>

<dfn attribute for="VRSession">createParameters</dfn>

<dfn attribute for="VRSession">depthNear</dfn>

<dfn attribute for="VRSession">depthFar</dfn>

<dfn attribute for="VRSession">baseLayer</dfn>

<dfn method for="VRSession">getSourceProperties()</dfn>

<dfn method for="VRSession">createFrameOfReference()</dfn>

<dfn method for="VRSession">getDisplayPose()</dfn>

<dfn method for="VRSession">getPlayAreaBounds()</dfn>

<dfn method for="VRSession">endSession()</dfn>

<dfn attribute for="VRSession">onblur</dfn> is an <a>Event handler IDL attribute</a> for the {{blur}} event type.

<dfn attribute for="VRSession">onfocus</dfn> is an <a>Event handler IDL attribute</a> for the {{focus}} event type.

<dfn attribute for="VRSession">onresetpose</dfn> is an <a>Event handler IDL attribute</a> for the {{resetpose}} event type.

The VR Compositor {#compositor}
-----------------

The UA MUST maintain a <dfn>VR Compositor</dfn> which handles layer composition and frame timing. The compositor MUST use an independent rendering context who's state is isolated from that of the WebGL contexts provided as {{VRCanvasLayer}} sources to prevent the page from corruption the compositor state or reading back content from other pages.

There are no direct interfaces to the compositor, but applications may submit bitmaps to be composited via the layer system and observe the frame timing via calls to {{VRCanvasLayer/commit()}}. The compositor consists of two different loops, assumed to be running in separate threads or processes. The <dfn>Frame Loop</dfn>, which drives the page script, and the <dfn>Render Loop</dfn>, which continuously presents imagery provided by the Frame Loop to the VR Display. The render loop maintains it's own copy of the session's layer list. Communication between the two loops is synchronized with a lock that limits access to the render loop's layer list.

Both loops are started when a session is successfully created. The compositor's render loop goes through the following steps:

 1. The layer lock is acquired.
 1. The render loop's layer list images are composited and presented to the display.
 1. The layer lock is released.
 1. Notify the frame loop that a frame has been completed.
 1. return to step 1.

The render loop MUST throttle it's throughput to the refresh rate of the VR Display. The exact point in the loop that is most effective to block at may differ between platforms, so no perscription is made for when that should happen.

Upon session creation, the following steps are taken to start the frame loop:

 1. A new promise is created and set as the session's current frame promise. The current frame promise is returned any time {{VRCanvasLayer/commit()}} is called.
 1. The {{sessionchange}} event is fired.
 1. The promise returned from {{requestSession()}} is resolved.

Then, the frame loop performs the following steps while the session is active:

 1. The render loop's layer lock is acquired.
 1. Any dirty layers in the session's layer list are copied to the render loop's layer list.
 1. The render loop's layer lock is released.
 1. Wait for the render loop to signal that a frame has been completed.
 1. The session's current frame promise is set as the the previous frame promise.
 1. A new promise is created and set as the session's current frame promise.
 1. The previous frame promise is resolved.
 1. Once the promise has been resolved, return to step 1.


Layers {#layers}
======

VRLayer {#vrlayer-interface}
-------

<pre class="idl">
interface VRLayer {};
</pre>

A {{VRLayer}} defines a source of bitmap images and a description of how the image is to be rendered in the {{VRDisplay}}. Initially only one type of layer, the {{VRCanvasLayer}}, is defined but future revisions of the spec may extend the available layer types.

VRCanvasLayer {#vrcanvaslayer-interface}
-------

<pre class="idl">
typedef (HTMLCanvasElement or
         OffscreenCanvas) VRCanvasSource;

[Constructor(VRSession session, optional VRCanvasSource source)]
interface VRCanvasLayer : VRLayer {
  // Attributes
  attribute VRCanvasSource source;

  // Methods
  void setLeftBounds(float left, float bottom, float right, float top);
  FrozenArray&lt;float&gt; getLeftBounds();

  void setRightBounds(float left, float bottom, float right, float top);
  FrozenArray&lt;float&gt; getRightBounds();

  Promise&lt;DOMHighResTimeStamp&gt; commit();
};
</pre>

The <dfn attribute for="VRCanvasLayer">source</dfn> defines a canvas whose contents will be presented by the {{VRDisplay}} when {{commit()}} is called.

Upon being set as the source of a {{VRCanvasLayer}} the source's context MAY be lost. Additionally the current backbuffer of the source's context MAY be lost, even if the context was created with the <code>preserveDrawingBuffer</code> context creation attribute set to <code>true</code>.

Note: In order to make use of a canvas in the event of context loss, the application should handle the <code>webglcontextlost</code> event on the source canvas and prevent the event's default behavior. The application should then listen for a <code>webglcontextrestored</code> event to be fired and reload any necessary graphical resources in response.

The layer describes two viewports: the <dfn for="VRCanvasLayer">Left Bounds</dfn> and <dfn for="VRCanvasLayer">Right Bounds</dfn>. Each bounds contians four values (|left|, |bottom|, |right|, |top|) defining the texture bounds within the source canvas to present to the related eye in UV space (0.0 - 1.0) with the bottom left corner of the canvas at (0, 0) and the top right corner of the canvas at (1, 1). If the left bound is greater or equal to the right bound or the bottom bound is greater than or equal to the top bound the viewport is considered to be empty and no content from this layer will be shown on the related eye of the {{VRDisplay}}.

The [=left bounds=] MUST default to <code>[0.0, 0.0, 0.5, 1.0]</code> and the [=right bounds=] MUST default to <code>[0.5, 0.0, 1.0, 1.0]</code>.

Invoking the <dfn method for="VRCanvasLayer">setLeftBounds()</dfn> method with a given |left|, |bottom|, |right|, and |top| value sets the values of the [=left bounds=] |left|, |bottom|, |right|, and |top| respectively.

Invoking the <dfn method for="VRCanvasLayer">setRightBounds()</dfn> method with a given |left|, |bottom|, |right|, and |top| value sets the values of the [=right bounds=] |left|, |bottom|, |right|, and |top| respectively.

Invoking the <dfn method for="VRCanvasLayer">getLeftBounds()</dfn> method returns a {{FrozenArray}} of floats containing the [=left bounds=] to |left|, |bottom|, |right|, and |top| values in that order.

Invoking the <dfn method for="VRCanvasLayer">getRightBounds()</dfn> method returns a {{FrozenArray}} of floats containing the [=right bounds=] to |left|, |bottom|, |right|, and |top| values in that order.

<dfn method for="VRCanvasLayer">commit()</dfn> captures the {{VRCanvasLayer/source}} canvas's bitmap and submits it to the [=VR compositor=]. Calling {{commit()}} has the same effect on the source canvas as any other operation that uses it's bitmap, and canvases created without <code>preserveDrawingBuffer</code> set to <code>true</code> will be cleared.

VRSourceProperties {#vrsourceproperties-interface}
------------------

<pre class="idl">
interface VRSourceProperties {
  readonly attribute float scale;
  readonly attribute unsigned long width;
  readonly attribute unsigned long height;
};
</pre>

The {{VRSourceProperties}} interface describes the ideal dimensions of a layer image for a {{VRDisplay}}, taking into account the native resolution of the display and the distortion required to counteract an distortion introduced by the display's optics.

<dfn attribute for="VRSourceProperties">scale</dfn> returns the scale provided to {{getSourceProperties()}} if one was given. If not, it returns the scale recommended by the system.

<dfn attribute for="VRSourceProperties">width</dfn> and <dfn attribute for="VRSourceProperties">height</dfn> describe the dimensions a layer image should ideally be in order to appear on the display at a {{VRSourceProperties/scale}}:1 pixel ratio. The given dimenions MUST only account for a single eye.

<div class="example">
Because a {{VRCanvasLayer}} contains content for both eyes, the {{VRCanvasLayer/source}} canvas should be twice the size perscribed by the {{VRSourceProperties}} in order to get the desired output.

<pre class="lang-js">
var sourceProperties = vrSession.getSourceProperties();

canvasLayer.source.width = sourceProperties.width * 2;
canvasLayer.source.height = sourceProperties.height;
</pre>
</div>

Coordinate Systems {#coordinatesystems}
==================

VRCoordinateSystem {#vrcoordinatesystem-interface}
------------------

<pre class="idl">
interface VRCoordinateSystem {
  Float32Array? getTransformTo(VRCoordinateSystem other);
};
</pre>

VRFrameOfReference {#vrframeofreference-interface}
------------------

<pre class="idl">
enum VRFrameOfReferenceType {
  "HeadModel",
  "EyeLevel",
  "FloorLevel",
};

interface VRFrameOfReference : VRCoordinateSystem {
  readonly attribute VRFrameOfReferenceType type;
};
</pre>


VRDisplayPose {#vrdisplaypose-interface}
-------------

<pre class="idl">
interface VRDisplayPose {
  readonly attribute Float32Array leftProjectionMatrix;
  readonly attribute Float32Array leftViewMatrix;

  readonly attribute Float32Array rightProjectionMatrix;
  readonly attribute Float32Array rightViewMatrix;

  readonly attribute Float32Array poseModelMatrix;
};
</pre>

<dfn attribute for="VRDisplayPose">leftProjectionMatrix</dfn>
<dfn attribute for="VRDisplayPose">rightProjectionMatrix</dfn>

<dfn attribute for="VRDisplayPose">leftViewMatrix</dfn>
<dfn attribute for="VRDisplayPose">rightViewMatrix</dfn>

<dfn attribute for="VRDisplayPose">poseModelMatrix</dfn>


VRPlayAreaBounds {#vrplayareabounds-interface}
----------------

The {{VRPlayAreaBounds}} interface describes the size and shape of the user's play area for devices that support room-scale experiences. This is the area that the user can be expected to safely be able to move within.

<pre class="idl">
interface VRPlayAreaBounds {
  readonly attribute float minX;
  readonly attribute float maxX;
  readonly attribute float minZ;
  readonly attribute float maxZ;
};
</pre>

<dfn attribute for="VRPlayAreaBounds">minX</dfn>, <dfn attribute for="VRPlayAreaBounds">maxX</dfn>, <dfn attribute for="VRPlayAreaBounds">minZ</dfn>, and <dfn attribute for="VRPlayAreaBounds">maxZ</dfn> define an axis-aligned rectangle on the floor relative to the origin of the {{VRCoordinateSystem}} the bounds were queried with. The origin MAY be outside the bounds rectangle. {{minX}} MUST be less than {{maxX}} and {{minZ}} MUST be less than {{maxZ}}.

Note: Content should not require the user to move beyond these bounds; however, it is possible for the user to ignore the bounds resulting in position values outside of the rectangle they describe.


Events {#events}
========

VREvent {#vrevent-interface}
-------

<pre class="idl">
[Constructor(DOMString type, VREventInit eventInitDict)]
interface VREvent : Event {
  readonly attribute VRDisplay display;
  readonly attribute VRSession? session;
};

dictionary VREventInit : EventInit {
  required VRDisplay display;
  VRSession? session;
};
</pre>

<dfn attribute for="VREvent">display</dfn>
The {{VRDisplay}} associated with this event.

<dfn attribute for="VREvent">session</dfn>
The {{VRSession}} associated with this event, if any.

Event Types {#event-types}
-----------

The UA MUST provide the following new events. The corresponding events must be of type {{VREvent}}. Registration for and firing of the events must follow the usual behavior of DOM4 Events.

The UA MAY fire a <dfn event for="VR">displayconnect</dfn> event on the {{VR}} object to indicate that a {{VRDisplay}} has been connected.

The UA MAY dispatch a <dfn event for="VR">displaydisconnect</dfn> event on the {{VR}} object to indicate that a {{VRDisplay}} has been disconnected.

The UA MAY dispatch a <dfn event for="VR">navigate</dfn> event on the {{VR}} object to indicate that the current page has been navigated to from a browsing context that was actively presenting VR content. The event's {{VREvent/session}} MUST be an instance of a {{VRSession}} with identical capabilities to the active session from the previous page, such that presenting to the session will feel like a seamless transition to the user.

The UA MUST dispatch a <dfn event for="VRDisplay">sessionchange</dfn> event on a {{VRDisplay}} to indicate that the {{VRDisplay}} has begun or ended a new {{VRSession}}. This event should not fire on subsequent calls to {{requestSession()}} if the returned session is the same as the current {{activeSession}}.

The UA MAY dispatch a <dfn event for="VRDisplay">activate</dfn> event on a {{VRDisplay}} to indicate that something has occurred which suggests the {{VRDisplay}} should be begin a presenting session. For example, if the {{VRDisplay}} is capable of detecting when the user has put it on, this event SHOULD fire when they do so.

The UA MAY dispatch a <dfn event for="VRDisplay">deactivate</dfn> event on a {{VRDisplay}} to indicate that something has occurred which suggests the {{VRDisplay}} should end the active session. For example, if the {{VRDisplay}} is capable of detecting when the user has taken it off, this event SHOULD fire when they do so.

A UA MAY dispatch a <dfn event for="VRSession">blur</dfn> event on a {{VRSession}} to indicate that presentation to the {{VRSession}} by the page has been suspended by the UA, OS, or VR hardware. While a {{VRSession}} is blurred it remains active but it may have it's frame production throttled. This is to prevent tracking while the user interacts with potentially sensitive UI. For example: The UA SHOULD blur the presenting application when the user is typing a URL into the browser with a virtual keyboard, otherwise the presenting page may be able to guess the URL the user is entering by tracking their head motions.

A UA MAY dispatch a <dfn event for="VRSession">focus</dfn> event on a {{VRSession}} to indicate that presentation to the {{VRSession}} by the page has resumed after being suspended.

A UA MUST dispatch a <dfn event for="VRSession">resetpose</dfn> event on a {{VRSession}} when the system resets the {{VRDisplay}}'s position or orientation.

Navigator interface extension {#navigator-interface}
=============================

<pre class="idl">
partial interface Navigator {
  [SameObject] readonly attribute VR vr;
};
</pre>

